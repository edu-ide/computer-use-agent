"""
ì¿ íŒ¡ ìƒí’ˆ ìˆ˜ì§‘ ì›Œí¬í”Œë¡œìš° - LangGraph ê¸°ë°˜

Letta ë©”ëª¨ë¦¬ í†µí•©:
- ì›Œí¬í”Œë¡œìš° ì‹œì‘ ì‹œ Letta ì—ì´ì „íŠ¸ ìƒì„±
- ê° ë…¸ë“œ ì‹¤í–‰ ì‹œ ë©”ëª¨ë¦¬ ë¸”ë¡ ì—…ë°ì´íŠ¸
- VLM ì—ì´ì „íŠ¸ì— ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
"""

import asyncio
from datetime import datetime
from typing import Any, Callable, Dict, List, Optional

from .workflow_base import (
    WorkflowBase,
    WorkflowConfig,
    WorkflowNode,
    WorkflowState,
    NodeResult,
    NodeStatus,
)
from ..services.coupang_db_service import get_coupang_db
from ..services.letta_memory_service import (
    get_letta_memory_service,
    WorkflowMemoryConfig,
    LettaMemoryService,
)
from ..services.node_reuse_analyzer import (
    get_node_reuse_analyzer,
    NodeReuseAnalyzer,
    ReuseDecision,
)
from ..services.orchestrator_service import (
    get_orchestrator_service,
    OrchestratorService,
    ExecutionStrategy,
    ExecutionDecision,
    ErrorAction,
    WorkflowReport,
)
from ..services.agent_activity_log import (
    log_vlm,
    log_memory,
    ActivityType,
)
from ..services.vlm_agent_runner import VLMStepLog
from ..models.coupang_models import CoupangProduct


class CoupangCollectWorkflow(WorkflowBase):
    """
    ì¿ íŒ¡ ë¹„ë¡œì¼“ë°°ì†¡ ìƒí’ˆ ìˆ˜ì§‘ ì›Œí¬í”Œë¡œìš°

    Flow:
    1. open_coupang - ì¿ íŒ¡ ì—´ê¸°
    2. search_keyword - í‚¤ì›Œë“œ ê²€ìƒ‰
    3. analyze_page - í˜ì´ì§€ ë¶„ì„ ë° ìƒí’ˆ ìˆ˜ì§‘
    4. next_page - ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™ (loop back to analyze_page)
    5. find_related - ì—°ê´€ í‚¤ì›Œë“œ íƒìƒ‰
    6. complete - ì™„ë£Œ
    """

    def __init__(self, agent_runner=None):
        """
        Args:
            agent_runner: VLMAgentRunner ì¸ìŠ¤í„´ìŠ¤
        """
        super().__init__()
        self._agent_runner = agent_runner
        self._db = get_coupang_db()
        self._on_step_callback: Optional[Callable] = None

        # Letta ë©”ëª¨ë¦¬ ì„œë¹„ìŠ¤
        self._letta: LettaMemoryService = get_letta_memory_service()
        self._letta_initialized: bool = False

        # ë…¸ë“œ ì¬ì‚¬ìš© ë¶„ì„ê¸° (ìë™ í•™ìŠµ)
        self._reuse_analyzer: NodeReuseAnalyzer = get_node_reuse_analyzer()
        self._auto_learn_reuse: bool = True  # ì¬ì‚¬ìš© ì„¤ì • ìë™ í•™ìŠµ í™œì„±í™”

        # Orchestrator ì„œë¹„ìŠ¤ (ì‹¤í–‰ ì „ëµ ê²°ì •)
        self._orchestrator: OrchestratorService = get_orchestrator_service()
        self._use_orchestrator: bool = True  # Orchestrator ì‚¬ìš© ì—¬ë¶€ (8081 ì„œë²„ í•„ìš”)

        # VLMAgentRunnerì— Orchestrator ì£¼ì… (Step-level interventionì„ ìœ„í•´)
        if self._agent_runner and hasattr(self._agent_runner, "_orchestrator") and self._agent_runner._orchestrator is None:
            self._agent_runner._orchestrator = self._orchestrator

    def set_step_callback(self, callback: Callable):
        """ìŠ¤í… ì½œë°± ì„¤ì • - ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸ìš©"""
        self._on_step_callback = callback

    async def _init_letta_memory(self, keyword: str):
        """Letta ë©”ëª¨ë¦¬ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        if self._letta_initialized:
            return

        try:
            # ì¿ íŒ¡ ì›Œí¬í”Œë¡œìš°ìš© ë©”ëª¨ë¦¬ ì„¤ì • ìƒì„±
            config = WorkflowMemoryConfig.for_coupang(keyword=keyword)

            # Letta ì—ì´ì „íŠ¸ ìƒì„±
            await self._letta.create_workflow_agent(config)
            self._letta_initialized = True
            print(f"[CoupangWorkflow] Letta ë©”ëª¨ë¦¬ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {keyword}")

        except Exception as e:
            print(f"[CoupangWorkflow] Letta ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì‹¤íŒ¨ (í´ë°± ëª¨ë“œ ì‚¬ìš©): {e}")
            self._letta_initialized = True  # í´ë°± ëª¨ë“œì—ì„œë„ ì´ˆê¸°í™”ëœ ê²ƒìœ¼ë¡œ ì²˜ë¦¬

    async def _update_memory_on_node_start(self, node_name: str, state: WorkflowState):
        """ë…¸ë“œ ì‹œì‘ ì‹œ ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸"""
        if not self._letta_initialized:
            return

        workflow_id = self.config.id
        data = state.get("data", {})
        completed_nodes = state.get("completed_nodes", [])

        # ì§„í–‰ë¥  ê³„ì‚°
        total_nodes = len(self.nodes) - 2  # error_handler, complete ì œì™¸
        progress = int((len(completed_nodes) / total_nodes) * 100) if total_nodes > 0 else 0

        # ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì—…ë°ì´íŠ¸
        await self._letta.update_workflow_state(
            workflow_id=workflow_id,
            current_node=node_name,
            completed_nodes=completed_nodes,
            progress=progress,
            additional_info=f"- í‚¤ì›Œë“œ: {data.get('current_keyword', '-')}",
        )

        # íƒœìŠ¤í¬ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        node_config = self._get_node_config(node_name)
        if node_config:
            await self._letta.update_task_context(
                workflow_id=workflow_id,
                status="ì‹¤í–‰ ì¤‘",
                current_goal=node_config.description,
                next_action=node_config.display_name,
            )

    async def _update_memory_on_node_complete(
        self,
        node_name: str,
        state: WorkflowState,
        result: NodeResult,
    ):
        """ë…¸ë“œ ì™„ë£Œ ì‹œ ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸"""
        if not self._letta_initialized:
            return

        workflow_id = self.config.id
        data = state.get("data", {})

        # ìˆ˜ì§‘ ë°ì´í„° ì—…ë°ì´íŠ¸ (analyze_page, save_products ë…¸ë“œ)
        if node_name in ["analyze_page", "save_products"]:
            collected_count = data.get("collected_count", 0)
            pages_analyzed = data.get("pages_analyzed", 0)

            await self._letta.update_collected_data(
                workflow_id=workflow_id,
                total_items=collected_count,
                pages_analyzed=pages_analyzed,
            )

        # ì—ëŸ¬ ë°œìƒ ì‹œ ì—ëŸ¬ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        if not result.success and result.error:
            await self._letta.add_error(
                workflow_id=workflow_id,
                error=f"[{node_name}] {result.error}",
            )

        # ì¬ì‚¬ìš© í•™ìŠµ: ì‹¤í–‰ ê²°ê³¼ ê¸°ë¡
        if self._auto_learn_reuse:
            await self._record_and_learn_reuse(node_name, state, result)

    def _get_recent_execution_history(self, limit: int = 5) -> List[Dict[str, Any]]:
        """ìµœê·¼ ì‹¤í–‰ ì´ë ¥ ë°˜í™˜ (Orchestrator ì»¨í…ìŠ¤íŠ¸ìš©)"""
        history = []

        # node_logsì—ì„œ ìµœê·¼ ì‹¤í–‰ ì •ë³´ ì¶”ì¶œ
        node_logs = self._current_state.get("node_logs", {})
        completed_nodes = self._current_state.get("completed_nodes", [])

        for node_id in completed_nodes[-limit:]:
            logs = node_logs.get(node_id, [])
            success = len(logs) > 0 and not any(
                "error" in str(log).lower() for log in logs
            )
            history.append({
                "node_id": node_id,
                "success": success,
                "steps_count": len(logs),
            })

        return history

    async def _record_and_learn_reuse(
        self,
        node_name: str,
        state: WorkflowState,
        result: NodeResult,
    ):
        """ì‹¤í–‰ ê²°ê³¼ ê¸°ë¡ ë° ì¬ì‚¬ìš© ì„¤ì • í•™ìŠµ"""
        workflow_id = self.config.id
        execution_id = state.get("execution_id", "")
        parameters = state.get("parameters", {})
        node_logs = self._current_state.get("node_logs", {})
        steps_count = len(node_logs.get(node_name, []))

        # ì‹¤í–‰ ê²°ê³¼ ê¸°ë¡
        self._reuse_analyzer.record_execution(
            node_id=node_name,
            workflow_id=workflow_id,
            execution_id=execution_id,
            success=result.success,
            steps_count=steps_count,
            parameters=parameters,
            data_produced=result.data if result.data else {},
            error=result.error,
        )

        # ë¶„ì„ ë° í•™ìŠµ (ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìŒ“ì´ë©´)
        analysis = self._reuse_analyzer.analyze_node(node_name, workflow_id)

        if analysis.decision != ReuseDecision.UNCERTAIN:
            # Letta ë©”ëª¨ë¦¬ì— í•™ìŠµëœ ì„¤ì • ì €ì¥
            settings = {
                "decision": analysis.decision.value,
                "confidence": analysis.confidence,
                "reason": analysis.reason,
                "reusable": analysis.recommended_reusable,
                "reuse_trace": analysis.recommended_reuse_trace,
                "share_memory": analysis.recommended_share_memory,
                "cache_key_params": analysis.recommended_cache_key_params,
            }

            await self._letta.update_node_reuse_settings(
                workflow_id=workflow_id,
                node_id=node_name,
                settings=settings,
            )

            print(f"[CoupangWorkflow] {node_name}: ì¬ì‚¬ìš© ì„¤ì • í•™ìŠµë¨ - {analysis.decision.value} ({analysis.confidence:.1%})")

    async def _get_memory_context(self) -> str:
        """VLM ì—ì´ì „íŠ¸ì— ì „ë‹¬í•  ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ"""
        if not self._letta_initialized:
            return ""

        return await self._letta.get_context_for_agent(self.config.id)

    async def _cleanup_letta_memory(self):
        """ì›Œí¬í”Œë¡œìš° ì¢…ë£Œ ì‹œ Letta ë©”ëª¨ë¦¬ ì •ë¦¬ (ì•ˆì „ ëª¨ë“œ)"""
        if self._letta_initialized:
            try:
                # íƒ€ì„ì•„ì›ƒ 2ì´ˆë¡œ ì œí•œ
                await asyncio.wait_for(self._letta.cleanup_agent(self.config.id), timeout=2.0)
            except Exception as e:
                print(f"[CoupangWorkflow] ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨ (ë¬´ì‹œë¨): {e}")
            finally:
                self._letta_initialized = False

    @property
    def config(self) -> WorkflowConfig:
        return WorkflowConfig(
            id="coupang-collect",
            name="ì¿ íŒ¡ ìƒí’ˆ ìˆ˜ì§‘",
            description="í‚¤ì›Œë“œë¡œ ì¿ íŒ¡ì—ì„œ ë¡œì¼“ë°°ì†¡ì´ ì•„ë‹Œ ìƒí’ˆì„ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.",
            icon="ShoppingCart",
            color="#e31937",
            category="e-commerce",
            parameters=[
                {
                    "name": "keyword",
                    "type": "string",
                    "label": "ê²€ìƒ‰ í‚¤ì›Œë“œ",
                    "placeholder": "ì˜ˆ: ë¬´ì„ ì´ì–´í°",
                    "required": True,
                },
                {
                    "name": "max_pages",
                    "type": "number",
                    "label": "ìµœëŒ€ í˜ì´ì§€ ìˆ˜",
                    "default": 5,
                    "min": 1,
                    "max": 20,
                },
                {
                    "name": "follow_related",
                    "type": "boolean",
                    "label": "ì—°ê´€ í‚¤ì›Œë“œ íƒìƒ‰",
                    "default": True,
                },
            ],
        )

    @property
    def nodes(self) -> List[WorkflowNode]:
        return [
            WorkflowNode(
                name="open_coupang",
                display_name="ì¿ íŒ¡ ì—´ê¸°",
                description="ì¿ íŒ¡ ì›¹ì‚¬ì´íŠ¸ ì—´ê¸°",
                on_success="search_keyword",
                on_failure="error_handler",
                node_type="vlm",
                timeout_sec=60,  # 1ë¶„
                avg_duration_sec=15,  # í‰ê·  15ì´ˆ
                instruction="""Open Chrome browser and navigate to https://www.coupang.com

Steps:
1. Use open_url("https://www.coupang.com") to navigate to Coupang
2. Wait for the page to fully load
3. Confirm you see the Coupang homepage""",
            ),
            WorkflowNode(
                name="search_keyword",
                display_name="í‚¤ì›Œë“œ ê²€ìƒ‰",
                description="í‚¤ì›Œë“œë¡œ ìƒí’ˆ ê²€ìƒ‰",
                on_success="analyze_page",
                on_failure="error_handler",
                node_type="vlm",
                timeout_sec=60,  # 1ë¶„
                avg_duration_sec=20,  # í‰ê·  20ì´ˆ
                instruction="""Search for "{keyword}" on Coupang:

Steps:
1. Find the search input box at the top of the page
2. Click on the search box
3. Type the keyword using write()
4. Press Enter to search using press(["enter"])
5. Wait for search results to load using wait(3)
6. Confirm search results are displayed""",
            ),
            WorkflowNode(
                name="analyze_page",
                display_name="í˜ì´ì§€ ë¶„ì„",
                description="í˜ì´ì§€ ë¶„ì„ ë° ë¹„ë¡œì¼“ ìƒí’ˆ ìˆ˜ì§‘",
                on_success="save_products",
                on_failure="error_handler",
                node_type="vlm",
                timeout_sec=180,  # 3ë¶„ (ìŠ¤í¬ë¡¤ + ë¶„ì„)
                avg_duration_sec=90,  # í‰ê·  1ë¶„ 30ì´ˆ
                instruction="""Analyze the current Coupang search results page:

Look at the product listings and identify products that do NOT have:
- ë¡œì¼“ë°°ì†¡ badge (blue rocket icon)
- ë¡œì¼“ì§êµ¬ badge
- ë¡œì¼“ì™€ìš° badge

These are "ì¼ë°˜ë°°ì†¡" (regular delivery) products.

Steps:
1. Scroll down slowly to see all products using scroll(500, 500, "down", 2)
2. Look for products without rocket badges
3. For each non-rocket product, extract:
   - Product name (ìƒí’ˆëª…)
   - Price (ê°€ê²©)
   - Product URL or ID if visible
   - Seller name if visible (íŒë§¤ì)
4. Continue scrolling to see more products
5. Return a list of found products in JSON format""",
            ),
            WorkflowNode(
                name="save_products",
                display_name="ìƒí’ˆ ì €ì¥",
                description="ìˆ˜ì§‘í•œ ìƒí’ˆì„ DBì— ì €ì¥",
                on_success="check_next_page",
                on_failure="error_handler",
                node_type="process",
                timeout_sec=30,  # 30ì´ˆ
                avg_duration_sec=2,  # í‰ê·  2ì´ˆ (ë¹ ë¥¸ DB ì‘ì—…)
            ),
            WorkflowNode(
                name="check_next_page",
                display_name="ë‹¤ìŒ í˜ì´ì§€",
                description="ë‹¤ìŒ í˜ì´ì§€ í™•ì¸",
                on_success="analyze_page",  # ë‹¤ìŒ í˜ì´ì§€ ìˆìœ¼ë©´ ë‹¤ì‹œ ë¶„ì„
                on_failure="find_related",   # ì—†ìœ¼ë©´ ì—°ê´€ í‚¤ì›Œë“œë¡œ
                node_type="vlm",
                timeout_sec=60,  # 1ë¶„
                avg_duration_sec=25,  # í‰ê·  25ì´ˆ
                instruction="""Check if there is a next page and navigate to it:

Steps:
1. Scroll to the bottom of the page to find pagination
2. Look for pagination controls (page numbers or "ë‹¤ìŒ" button)
3. If next page exists, click on the next page number or "ë‹¤ìŒ" button
4. Wait for the new page to load using wait(3)
5. If no next page available, report "no_next_page" """,
            ),
            WorkflowNode(
                name="find_related",
                display_name="ì—°ê´€ í‚¤ì›Œë“œ",
                description="ì—°ê´€ í‚¤ì›Œë“œ íƒìƒ‰",
                on_success="search_keyword",  # ì—°ê´€ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ê²€ìƒ‰
                on_failure="complete",  # ì—†ìœ¼ë©´ ì™„ë£Œ
                node_type="vlm",
                timeout_sec=60,  # 1ë¶„
                avg_duration_sec=30,  # í‰ê·  30ì´ˆ
                instruction="""Find related search keywords on Coupang:

Steps:
1. Look for "ì—°ê´€ ê²€ìƒ‰ì–´" or "ê´€ë ¨ ê²€ìƒ‰ì–´" section on the page
2. Or look for suggested keywords at the top or bottom of results
3. Find a new keyword that is not already searched
4. If you find a good related keyword, click on it
5. If no new related keywords exist, report "no_related_found" """,
            ),
            WorkflowNode(
                name="complete",
                display_name="ì™„ë£Œ",
                description="ìˆ˜ì§‘ ì™„ë£Œ",
                node_type="end",
                timeout_sec=10,
                avg_duration_sec=1,
            ),
            WorkflowNode(
                name="error_handler",
                display_name="ì—ëŸ¬ ì²˜ë¦¬",
                description="ì—ëŸ¬ ì²˜ë¦¬",
                node_type="error",
                timeout_sec=30,
                avg_duration_sec=5,
            ),
        ]

    @property
    def start_node(self) -> str:
        return "open_coupang"

    async def execute_node(self, node_name: str, state: WorkflowState) -> NodeResult:
        """ë…¸ë“œë³„ ì‹¤í–‰ ë¡œì§ (Letta ë©”ëª¨ë¦¬ í†µí•©)"""

        # ì²« ë²ˆì§¸ ë…¸ë“œì—ì„œ Letta ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        if node_name == self.start_node:
            keyword = state.get("parameters", {}).get("keyword", "")
            await self._init_letta_memory(keyword)

        # ë…¸ë“œ ì‹œì‘ ì‹œ ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
        await self._update_memory_on_node_start(node_name, state)

        handlers = {
            "open_coupang": self._open_coupang,
            "search_keyword": self._search_keyword,
            "analyze_page": self._analyze_page,
            "save_products": self._save_products,
            "check_next_page": self._check_next_page,
            "find_related": self._find_related,
            "complete": self._complete,
            "error_handler": self._error_handler,
        }

        handler = handlers.get(node_name)
        if handler:
            print(f"[Workflow] Executing node: {node_name}")
            result = await handler(state)
            print(f"[Workflow] Node completed: {node_name} (success={result.success}, next={result.next_node})")

            # ë…¸ë“œ ì™„ë£Œ ì‹œ ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
            await self._update_memory_on_node_complete(node_name, state, result)

            # ì™„ë£Œ ë˜ëŠ” ì—ëŸ¬ ë…¸ë“œì—ì„œ ë©”ëª¨ë¦¬ ì •ë¦¬
            if node_name in ["complete", "error_handler"]:
                await self._cleanup_letta_memory()

            return result

        return NodeResult(success=False, error=f"Unknown node: {node_name}")

    def _add_step_to_node_logs(self, state: WorkflowState, node_name: str, step_log):
        """ìŠ¤í… ë¡œê·¸ë¥¼ ë…¸ë“œ ë¡œê·¸ì— ì¶”ê°€

        Note: LangGraph stateëŠ” ë¶ˆë³€ì´ë¯€ë¡œ ì§ì ‘ ìˆ˜ì • ëŒ€ì‹  _current_stateë¥¼ ì—…ë°ì´íŠ¸
        """
        # í˜„ì¬ ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤ì˜ _current_stateì—ì„œ node_logs ê°€ì ¸ì˜¤ê¸°
        if not hasattr(self, '_current_state') or self._current_state is None:
            return {}

        node_logs = self._current_state.get("node_logs", {})
        if node_name not in node_logs:
            node_logs[node_name] = []

        # tool_callsë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        tool_calls_serializable = []
        if step_log.tool_calls:
            for tc in step_log.tool_calls:
                if hasattr(tc, 'model_dump'):
                    # Pydantic ëª¨ë¸ì¸ ê²½ìš°
                    tool_calls_serializable.append(tc.model_dump())
                elif hasattr(tc, '__dict__'):
                    # ì¼ë°˜ ê°ì²´ì¸ ê²½ìš°
                    tool_calls_serializable.append(str(tc))
                else:
                    tool_calls_serializable.append(str(tc))

        step_data = {
            "step_number": step_log.step_number,
            "timestamp": step_log.timestamp,
            "screenshot": step_log.screenshot,
            "thought": step_log.thought,
            "action": step_log.action,
            "observation": step_log.observation,
            "error": step_log.error,
            "tool_calls": tool_calls_serializable,
            "orchestrator_feedback": getattr(step_log, "orchestrator_feedback", None),
        }

        # ë””ë²„ê¹…: ìŠ¤í… ë°ì´í„° ë¡œê¹…
        print(f"[StepLog] {node_name} step {step_log.step_number}: "
              f"thought={bool(step_log.thought)}, "
              f"action={bool(step_log.action)}, "
              f"observation={bool(step_log.observation)}, "
              f"screenshot={bool(step_log.screenshot)}")
        if step_log.thought:
            print(f"  -> thought: {step_log.thought[:100]}...")

        node_logs[node_name].append(step_data)

        # _current_stateì— ì§ì ‘ ì—…ë°ì´íŠ¸ (WebSocket ì¡°íšŒ ì‹œ ì¦‰ì‹œ ë°˜ì˜)
        self._current_state["node_logs"] = node_logs

        if self._on_step_callback:
            self._on_step_callback(node_name, step_log)

        return node_logs

    def _get_node_config(self, node_name: str) -> Optional[WorkflowNode]:
        """ë…¸ë“œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
        for node in self.nodes:
            if node.name == node_name:
                return node
        return None

    async def _run_vlm_instruction(
        self,
        instruction: str,
        state: WorkflowState,
        node_name: str,
    ) -> tuple[bool, Dict[str, Any], Optional[str]]:
        """
        VLM ëª…ë ¹ ì‹¤í–‰ (Orchestrator íŒ¨í„´)

        ì‹¤í–‰ íë¦„:
        1. Orchestratorê°€ ì‹¤í–‰ ì „ëµ ê²°ì •
        2. CACHE_HIT â†’ ì¦‰ì‹œ ë°˜í™˜ (VLM í˜¸ì¶œ ì—†ìŒ!)
        3. RULE_BASED â†’ ê·œì¹™ ê¸°ë°˜ ì‹¤í–‰
        4. LOCAL_MODEL/CLOUD â†’ VLM ì‹¤í–‰
        """
        import time
        start_time = time.time()

        node_config = self._get_node_config(node_name)
        params = state.get("parameters", {})
        decision = None  # Orchestrator decision

        # í˜„ì¬ ì‹¤í–‰ ID (Orchestrator ë¡œê·¸ìš©)
        current_execution_id = state.get("execution_id", self.config.id)

        # === 1. Orchestrator ê²°ì • (ìºì‹œ ì²´í¬ í¬í•¨) ===
        if self._use_orchestrator:
            # ë¹„ë™ê¸° Orchestrator-8B ëª¨ë¸ ì‚¬ìš© (ì„œë²„ ì‹¤í–‰ ì¤‘ì¼ ë•Œ)
            # ì„œë²„ ë¯¸ì‹¤í–‰ì‹œ ìë™ìœ¼ë¡œ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ fallback
            decision = await self._orchestrator.decide_async(
                workflow_id=self.config.id,
                node_id=node_name,
                instruction=instruction,
                params=params,
                node_config=node_config,
                execution_id=current_execution_id,  # ì‹¤í–‰ ID ì „ë‹¬
                execution_history=self._get_recent_execution_history(),
            )
            
            # Calculate decision time
            decision_time = int((time.time() - start_time) * 1000)

            # Orchestrator ê²°ì •ì„ ë¡œê·¸ì— ê¸°ë¡ (Step 0)
            if decision:
                self._add_step_to_node_logs(state, node_name, VLMStepLog(
                    step_number=0,
                    timestamp=datetime.now().isoformat(),
                    thought=f"Orchestrator Decision: {decision.strategy.value}\nReason: {decision.reason}\nTime: {decision_time}ms",
                    action=f"[Strategy] {decision.strategy.value}",
                    observation=f"Model: {decision.model_id}\nReuse: {decision.reuse_trace}\nTime: {decision_time}ms",
                    orchestrator_feedback={
                        "action": "strategy_selected",
                        "reason": f"{decision.reason} ({decision_time}ms)",
                        "learned_pattern": decision.strategy.value
                    }
                ))

            # CACHE_HIT: ì¦‰ì‹œ ë°˜í™˜! (VLM í˜¸ì¶œ ì—†ìŒ, íŒë‹¨ë„ ìŠ¤í‚µ)
            if decision.strategy == ExecutionStrategy.CACHE_HIT:
                elapsed_ms = int((time.time() - start_time) * 1000)
                print(f"[Orchestrator] {node_name}: âš¡ CACHE_HIT - {elapsed_ms}ms (VLM ìŠ¤í‚µ)")

                cached = decision.cached_result
                return True, cached.get("data", {}), None

            # RULE_BASED: ê·œì¹™ ê¸°ë°˜ ì‹¤í–‰ (VLM ì—†ì´)
            if decision.strategy == ExecutionStrategy.RULE_BASED:
                elapsed_ms = int((time.time() - start_time) * 1000)
                print(f"[Orchestrator] {node_name}: ğŸ“‹ RULE_BASED - {elapsed_ms}ms")
                # TODO: ê·œì¹™ ê¸°ë°˜ ì‹¤í–‰ êµ¬í˜„
                # í˜„ì¬ëŠ” VLMìœ¼ë¡œ í´ë°±
                pass

            # ëª¨ë¸ ì„ íƒ ë¡œê¹…
            print(f"[Orchestrator] {node_name}: ğŸ¤– {decision.strategy.value} "
                  f"(model={decision.model_id}, reason={decision.reason})")

        # === 2. VLM ì‹¤í–‰ì´ í•„ìš”í•œ ê²½ìš° ===
        if not self._agent_runner:
            return True, {}, None

        def on_step(step_log):
            self._add_step_to_node_logs(state, node_name, step_log)

            # Activity Logì— ìŠ¤í… ì™„ë£Œ ê¸°ë¡
            if step_log.step_number > 0:
                log_vlm(
                    ActivityType.EXECUTION,
                    f"ìŠ¤í… {step_log.step_number} ì‹¤í–‰",
                    details={
                        "action": step_log.action,
                        "thought": step_log.thought[:50] + "..." if step_log.thought else None,
                    },
                    execution_id=current_execution_id,
                    node_id=node_name,
                    duration_ms=getattr(step_log, "duration_ms", None),
                )

            # ë™ê¸° ì½œë°±ì—ì„œ ë¹„ë™ê¸° ì‘ì—… ì•ˆì „í•˜ê²Œ ì‹¤í–‰
            try:
                loop = asyncio.get_running_loop()
                loop.create_task(self._update_observation_on_step(node_name, step_log))
            except RuntimeError:
                # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê±°ë‚˜ ìŠ¤í‚µ
                pass

        # ì¬ì‚¬ìš© ì„¤ì •: Orchestrator íŒë‹¨ > í•™ìŠµëœ ì„¤ì • > ê¸°ë³¸ê°’
        # Orchestratorê°€ ì´ë¯¸ decisionì— ì¬ì‚¬ìš© ì„¤ì •ì„ í¬í•¨í•¨
        if self._use_orchestrator and decision:
            # Orchestrator-8Bê°€ íŒë‹¨í•œ ì¬ì‚¬ìš© ì„¤ì • ì‚¬ìš©
            reusable = decision.reusable
            reuse_trace = decision.reuse_trace
            share_memory = decision.share_memory
            cache_key_params = decision.cache_key_params
            print(f"[Orchestrator] {node_name}: ì¬ì‚¬ìš©ì„¤ì • - "
                  f"reuse_trace={reuse_trace}, share_memory={share_memory}, "
                  f"cache_key_params={cache_key_params}")
        else:
            # Fallback: í•™ìŠµëœ ì„¤ì • ë˜ëŠ” ê¸°ë³¸ê°’
            learned_settings = self._reuse_analyzer.get_recommended_settings(
                node_name, self.config.id
            )
            use_learned = learned_settings.get("confidence", 0) > 0.7

            if use_learned:
                reusable = learned_settings.get("reusable", False)
                reuse_trace = learned_settings.get("reuse_trace", False)
                share_memory = learned_settings.get("share_memory", False)
                cache_key_params = learned_settings.get("cache_key_params", [])
            else:
                reusable = node_config.reusable if node_config else False
                reuse_trace = node_config.reuse_trace if node_config else False
                share_memory = node_config.share_memory if node_config else False
                cache_key_params = node_config.cache_key_params if node_config else []

        # ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸
        memory_context = ""
        if share_memory:
            memory_context = await self._get_memory_context()

        enhanced_instruction = instruction
        if memory_context:
            enhanced_instruction = f"""## ì´ì „ ì‘ì—… ì»¨í…ìŠ¤íŠ¸ (ë©”ëª¨ë¦¬)
{memory_context}

## í˜„ì¬ íƒœìŠ¤í¬
{instruction}"""

        # í™œë™ ë¡œê·¸: VLM ì‹¤í–‰ ì‹œì‘
        log_vlm(
            ActivityType.EXECUTION,
            f"{node_name} ì‹¤í–‰ ì‹œì‘",
            details={
                "instruction": instruction[:100] + "..." if len(instruction) > 100 else instruction,
                "share_memory": share_memory,
                "reuse_trace": reuse_trace,
            },
            execution_id=current_execution_id,
            node_id=node_name,
        )

        # VLM ì‹¤í–‰
        result = await self._agent_runner.run_instruction(
            enhanced_instruction,
            on_step=on_step,
            workflow_id=self.config.id,
            node_id=node_name,
            params=params,
            reuse_trace=reuse_trace,
            reusable=reusable,
            cache_key_params=cache_key_params,
            share_memory=share_memory,
        )

        # ì‹¤í–‰ ê²°ê³¼ ê¸°ë¡ (Orchestrator í†µê³„)
        elapsed_ms = int((time.time() - start_time) * 1000)
        if self._use_orchestrator:
            self._orchestrator.record_execution_result(
                workflow_id=self.config.id,
                node_id=node_name,
                strategy=decision.strategy if self._use_orchestrator else ExecutionStrategy.CLOUD_HEAVY,
                model_id=decision.model_id if self._use_orchestrator else None,
                success=result.success,
                actual_time_ms=elapsed_ms,
                actual_cost=0.0,  # TODO: ì‹¤ì œ ë¹„ìš© ê³„ì‚°
            )

        # Orchestratorë¡œ ê²°ê³¼ ê²€ì¦ (ë´‡ ê°ì§€ / ì‹¤íŒ¨ íŒ¨í„´ ì²´í¬)
        if result.success and self._use_orchestrator:
            # ë§ˆì§€ë§‰ ìŠ¤í…ì—ì„œ thought, observation ì¶”ì¶œ
            last_thought = None
            last_observation = None
            final_answer = result.data.get("final_answer") if result.data else None

            if result.steps and len(result.steps) > 0:
                last_step = result.steps[-1]
                last_thought = last_step.thought
                last_observation = last_step.observation

            is_valid, error_type, error_message = self._orchestrator.validate_execution_result(
                workflow_id=self.config.id,
                node_id=node_name,
                result_data=result.data or {},
                final_answer=final_answer,
                last_observation=last_observation,
                last_thought=last_thought,
            )

            if not is_valid:
                log_vlm(
                    ActivityType.ERROR,
                    f"{node_name} ê²€ì¦ ì‹¤íŒ¨: {error_message}",
                    details={
                        "error_type": error_type,
                        "error_message": error_message,
                    },
                    execution_id=current_execution_id,
                    node_id=node_name,
                    duration_ms=elapsed_ms,
                )
                return False, result.data, error_message

        # í™œë™ ë¡œê·¸: VLM ì‹¤í–‰ ì™„ë£Œ
        if result.success:
            log_vlm(
                ActivityType.EXECUTION,
                f"{node_name} ì™„ë£Œ",
                details={
                    "success": True,
                    "steps_count": len(result.data.get("steps", [])) if result.data else 0,
                    "reused": result.data.get("reused_from_cache", False) if result.data else False,
                },
                execution_id=current_execution_id,
                node_id=node_name,
                duration_ms=elapsed_ms,
            )
            if result.data.get("reused_from_cache"):
                print(f"[CoupangWorkflow] {node_name}: trace ìºì‹œì—ì„œ ì¬ì‚¬ìš©ë¨")
            return True, result.data, None
        else:
            log_vlm(
                ActivityType.ERROR,
                f"{node_name} ì‹¤íŒ¨: {result.error[:50] if result.error else 'Unknown'}",
                details={
                    "success": False,
                    "error": result.error,
                },
                execution_id=current_execution_id,
                node_id=node_name,
                duration_ms=elapsed_ms,
            )
            return False, result.data, result.error

    async def _run_vlm_with_error_handling(
        self,
        instruction: str,
        state: WorkflowState,
        node_name: str,
        max_retries: int = 3,
    ) -> tuple[bool, Dict[str, Any], Optional[str]]:
        """
        ì—ëŸ¬ í•¸ë“¤ë§ì´ í¬í•¨ëœ VLM ì‹¤í–‰

        Orchestratorê°€ ì—ëŸ¬ ë°œìƒ ì‹œ ì¬ì‹œë„/ìŠ¤í‚µ/ì¤‘ë‹¨ì„ ê²°ì •í•©ë‹ˆë‹¤.
        """
        retry_count = 0
        last_error = None
        current_strategy = None

        while retry_count <= max_retries:
            try:
                success, data, error = await self._run_vlm_instruction(
                    instruction, state, node_name
                )

                if success:
                    return True, data, None

                # ì‹¤íŒ¨ ì‹œ Orchestratorì—ê²Œ ì—ëŸ¬ í•¸ë“¤ë§ ê²°ì • ìš”ì²­
                if self._use_orchestrator and error:
                    error_decision = await self._orchestrator.handle_error(
                        workflow_id=self.config.id,
                        node_id=node_name,
                        error=Exception(error),
                        current_retry=retry_count,
                        strategy=current_strategy,
                    )

                    print(f"[Orchestrator] ì—ëŸ¬ í•¸ë“¤ë§: {error_decision.action.value} "
                          f"(retry={retry_count}/{max_retries})")

                    if error_decision.action == ErrorAction.RETRY:
                        retry_count += 1
                        last_error = error
                        print(f"[Orchestrator] {node_name} ì¬ì‹œë„ {retry_count}/{max_retries}")
                        await asyncio.sleep(2)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
                        continue

                    elif error_decision.action == ErrorAction.SKIP:
                        print(f"[Orchestrator] {node_name} ìŠ¤í‚µ (workflow ê³„ì†)")
                        return True, {"skipped": True, "reason": error}, None

                    elif error_decision.action == ErrorAction.FALLBACK:
                        # ë” ê°•ë ¥í•œ ëª¨ë¸ë¡œ ì¬ì‹œë„
                        if error_decision.fallback_strategy:
                            print(f"[Orchestrator] Fallback: {error_decision.fallback_strategy.value}")
                            retry_count += 1
                            continue

                    elif error_decision.action == ErrorAction.ABORT:
                        print(f"[Orchestrator] {node_name} ì¤‘ë‹¨ (workflow ì¤‘ë‹¨)")
                        return False, data, error

                    # ì‚¬ìš©ì ì•Œë¦¼ í•„ìš” ì‹œ
                    if error_decision.should_notify_user:
                        print(f"[Orchestrator] âš ï¸ ì‚¬ìš©ì í™•ì¸ í•„ìš”: {error}")

                # Orchestrator ì—†ìœ¼ë©´ ê¸°ë³¸ ë™ì‘: ì‹¤íŒ¨ ë°˜í™˜
                return False, data, error

            except asyncio.TimeoutError as e:
                retry_count += 1
                last_error = f"Timeout: {str(e)}"
                print(f"[Orchestrator] {node_name} íƒ€ì„ì•„ì›ƒ, ì¬ì‹œë„ {retry_count}/{max_retries}")
                if retry_count > max_retries:
                    return False, {}, last_error
                await asyncio.sleep(2)

            except Exception as e:
                retry_count += 1
                last_error = str(e)
                print(f"[Orchestrator] {node_name} ì˜ˆì™¸ ë°œìƒ: {e}")
                if retry_count > max_retries:
                    return False, {}, last_error
                await asyncio.sleep(2)

        return False, {}, last_error or "Max retries exceeded"

    async def run(self, parameters: Dict[str, Any], thread_id: str = "default") -> WorkflowState:
        """
        ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (Orchestrator ì¶”ì  ë° ë¦¬í¬íŠ¸ ìƒì„± í¬í•¨)

        Args:
            parameters: ì›Œí¬í”Œë¡œìš° íŒŒë¼ë¯¸í„°
            thread_id: ì‹¤í–‰ ìŠ¤ë ˆë“œ ID

        Returns:
            ìµœì¢… ì›Œí¬í”Œë¡œìš° ìƒíƒœ (ë¦¬í¬íŠ¸ í¬í•¨)
        """
        execution_id = f"{self.config.id}-{thread_id}"

        # Orchestrator ì¶”ì  ì‹œì‘
        if self._use_orchestrator:
            total_nodes = len([n for n in self.nodes
                              if n.node_type == "vlm"])  # VLM ë…¸ë“œë§Œ ì¹´ìš´íŠ¸
            self._orchestrator.start_workflow_tracking(
                workflow_id=self.config.id,
                execution_id=execution_id,
                total_nodes=total_nodes,
            )

        try:
            # ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            final_state = await super().run(parameters, thread_id)

            # ë¦¬í¬íŠ¸ ìƒì„±
            if self._use_orchestrator:
                try:
                    report = await self._orchestrator.generate_report(
                        execution_id=execution_id,
                        final_status=final_state.get("status", "unknown"),
                    )
                    final_state["report"] = report.to_dict()
                    print(f"\n{report.summary}")
                    if report.recommendations:
                        print("ê¶Œì¥ì‚¬í•­:")
                        for rec in report.recommendations:
                            print(f"  - {rec}")
                except Exception as e:
                    print(f"[Orchestrator] ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")

            return final_state

        finally:
            # ì •ë¦¬
            if self._use_orchestrator:
                self._orchestrator.cleanup_execution(execution_id)

    async def _update_observation_on_step(self, node_name: str, step_log):
        """ìŠ¤í… ì‹¤í–‰ ì‹œ ê´€ì°° ê¸°ë¡ ì—…ë°ì´íŠ¸"""
        if not self._letta_initialized:
            return

        try:
            # thoughtë‚˜ observationì´ ìˆìœ¼ë©´ ê¸°ë¡
            observation = step_log.thought or step_log.observation
            if observation:
                await self._letta.add_observation(
                    workflow_id=self.config.id,
                    current_page=node_name,
                    observation=observation[:200],  # 200ìë¡œ ì œí•œ
                )
        except Exception as e:
            # ê´€ì°° ê¸°ë¡ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ (ë©”ì¸ ë¡œì§ì— ì˜í–¥ ì—†ìŒ)
            pass

    async def _open_coupang(self, state: WorkflowState) -> NodeResult:
        """ì¿ íŒ¡ ì›¹ì‚¬ì´íŠ¸ ì—´ê¸°"""
        try:
            instruction = """
            Open Chrome browser and navigate to https://www.coupang.com

            Steps:
            1. Use open_url("https://www.coupang.com") to navigate to Coupang
            2. Wait for the page to fully load
            3. Confirm you see the Coupang homepage
            """

            success, data, error = await self._run_vlm_instruction(
                instruction, state, "open_coupang"
            )

            if not success:
                return NodeResult(success=False, error=error)

            return NodeResult(
                success=True,
                data={"coupang_opened": True}
            )
        except Exception as e:
            return NodeResult(success=False, error=str(e))

    async def _search_keyword(self, state: WorkflowState) -> NodeResult:
        """í‚¤ì›Œë“œ ê²€ìƒ‰"""
        try:
            parameters = state.get("parameters", {})
            data = state.get("data", {})

            # í˜„ì¬ í‚¤ì›Œë“œ (ì—°ê´€ í‚¤ì›Œë“œ ë˜ëŠ” ì›ë˜ í‚¤ì›Œë“œ)
            keyword = data.get("current_keyword") or parameters.get("keyword")

            if not keyword:
                return NodeResult(success=False, error="ê²€ìƒ‰ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤")

            instruction = f"""
            Search for "{keyword}" on Coupang:

            Steps:
            1. Find the search input box at the top of the page
            2. Click on the search box
            3. Type "{keyword}" using write("{keyword}")
            4. Press Enter to search using press(["enter"])
            5. Wait for search results to load using wait(3)
            6. Confirm search results are displayed
            """

            success, data_result, error = await self._run_vlm_instruction(
                instruction, state, "search_keyword"
            )

            if not success:
                return NodeResult(success=False, error=error)

            return NodeResult(
                success=True,
                data={
                    "current_keyword": keyword,
                    "current_page": 1,
                    "searched_keywords": state.get("data", {}).get("searched_keywords", []) + [keyword],
                }
            )
        except Exception as e:
            return NodeResult(success=False, error=str(e))

    async def _analyze_page(self, state: WorkflowState) -> NodeResult:
        """í˜ì´ì§€ ë¶„ì„ ë° ìƒí’ˆ ìˆ˜ì§‘"""
        try:
            data = state.get("data", {})
            keyword = data.get("current_keyword")
            current_page = data.get("current_page", 1)

            instruction = f"""
            Analyze the current Coupang search results page for "{keyword}" (Page {current_page}):

            Look at the product listings and identify products that do NOT have:
            - ë¡œì¼“ë°°ì†¡ badge (blue rocket icon)
            - ë¡œì¼“ì§êµ¬ badge
            - ë¡œì¼“ì™€ìš° badge

            These are "ì¼ë°˜ë°°ì†¡" (regular delivery) products.

            Steps:
            1. Scroll down slowly to see all products using scroll(500, 500, "down", 2)
            2. Look for products without rocket badges
            3. For each non-rocket product, extract:
               - Product name (ìƒí’ˆëª…)
               - Price (ê°€ê²©)
               - Product URL or ID if visible
               - Seller name if visible (íŒë§¤ì)
            4. Continue scrolling to see more products
            5. Return a list of found products in JSON format

            Return the products as a JSON array with keys: name, price, url, seller
            """

            success, data_result, error = await self._run_vlm_instruction(
                instruction, state, "analyze_page"
            )

            if not success:
                return NodeResult(success=False, error=error)

            # VLMì´ ìˆ˜ì§‘í•œ ìƒí’ˆ ëª©ë¡ (ì‹¤ì œë¡œëŠ” íŒŒì‹± í•„ìš”)
            collected_products = data_result.get("products", [])

            return NodeResult(
                success=True,
                data={
                    "pending_products": collected_products,  # ì €ì¥ ëŒ€ê¸° ìƒí’ˆ
                    "pages_analyzed": data.get("pages_analyzed", 0) + 1,
                }
            )
        except Exception as e:
            return NodeResult(success=False, error=str(e))

    async def _save_products(self, state: WorkflowState) -> NodeResult:
        """ìˆ˜ì§‘í•œ ìƒí’ˆì„ DBì— ì €ì¥"""
        try:
            data = state.get("data", {})
            parameters = state.get("parameters", {})
            keyword = data.get("current_keyword") or parameters.get("keyword")
            pending_products = data.get("pending_products", [])
            collected_count = data.get("collected_count", 0)

            saved_count = 0

            for product_data in pending_products:
                try:
                    # CoupangProduct ëª¨ë¸ë¡œ ë³€í™˜
                    product = CoupangProduct(
                        name=product_data.get("name", "Unknown"),
                        price=product_data.get("price", 0),
                        url=product_data.get("url", ""),
                        seller=product_data.get("seller", ""),
                        keyword=keyword,
                        is_rocket=False,  # ë¹„ë¡œì¼“ ìƒí’ˆë§Œ ìˆ˜ì§‘
                    )

                    # DBì— ì €ì¥
                    self._db.add_product(product)
                    saved_count += 1

                except Exception as e:
                    print(f"[CoupangWorkflow] ìƒí’ˆ ì €ì¥ ì‹¤íŒ¨: {e}")
                    continue

            return NodeResult(
                success=True,
                data={
                    "collected_count": collected_count + saved_count,
                    "last_saved_count": saved_count,
                    "pending_products": [],  # ì €ì¥ ì™„ë£Œ í›„ ë¹„ìš°ê¸°
                }
            )
        except Exception as e:
            return NodeResult(success=False, error=str(e))

    async def _check_next_page(self, state: WorkflowState) -> NodeResult:
        """ë‹¤ìŒ í˜ì´ì§€ í™•ì¸ ë° ì´ë™"""
        try:
            data = state.get("data", {})
            parameters = state.get("parameters", {})

            current_page = data.get("current_page", 1)
            max_pages = parameters.get("max_pages", 5)

            # ìµœëŒ€ í˜ì´ì§€ ë„ë‹¬ í™•ì¸
            if current_page >= max_pages:
                return NodeResult(
                    success=False,  # on_failure -> find_related
                    data={"max_pages_reached": True}
                )

            instruction = """
            Check if there is a next page and navigate to it:

            Steps:
            1. Scroll to the bottom of the page to find pagination
            2. Look for pagination controls (page numbers or "ë‹¤ìŒ" button)
            3. If next page exists, click on the next page number or "ë‹¤ìŒ" button
            4. Wait for the new page to load using wait(3)
            5. If no next page available, report "no_next_page"
            """

            success, data_result, error = await self._run_vlm_instruction(
                instruction, state, "check_next_page"
            )

            if not success or data_result.get("no_next_page"):
                return NodeResult(
                    success=False,  # on_failure -> find_related
                    data={"no_more_pages": True}
                )

            return NodeResult(
                success=True,  # on_success -> analyze_page
                data={"current_page": current_page + 1}
            )
        except Exception as e:
            return NodeResult(success=False, error=str(e))

    async def _find_related(self, state: WorkflowState) -> NodeResult:
        """ì—°ê´€ í‚¤ì›Œë“œ íƒìƒ‰"""
        try:
            parameters = state.get("parameters", {})
            data = state.get("data", {})

            # ì—°ê´€ í‚¤ì›Œë“œ íƒìƒ‰ ë¹„í™œì„±í™” ì‹œ
            if not parameters.get("follow_related", True):
                return NodeResult(
                    success=False,  # on_failure -> complete
                    data={"follow_related_disabled": True}
                )

            searched_keywords = data.get("searched_keywords", [])

            instruction = f"""
            Find related search keywords on Coupang:

            Steps:
            1. Look for "ì—°ê´€ ê²€ìƒ‰ì–´" or "ê´€ë ¨ ê²€ìƒ‰ì–´" section on the page
            2. Or look for suggested keywords at the top or bottom of results
            3. Find a new keyword that is NOT in this list: {searched_keywords}
            4. If you find a good related keyword, click on it
            5. If no new related keywords exist, report "no_related_found"
            """

            success, data_result, error = await self._run_vlm_instruction(
                instruction, state, "find_related"
            )

            if not success or data_result.get("no_related_found"):
                return NodeResult(
                    success=False,  # on_failure -> complete
                    data={"no_related_keywords": True}
                )

            new_keyword = data_result.get("related_keyword")
            if new_keyword and new_keyword not in searched_keywords:
                return NodeResult(
                    success=True,  # on_success -> search_keyword
                    data={
                        "current_keyword": new_keyword,
                        "current_page": 1,
                    }
                )

            return NodeResult(
                success=False,  # on_failure -> complete
                data={"no_related_keywords": True}
            )
        except Exception as e:
            return NodeResult(success=False, error=str(e))

    async def _complete(self, state: WorkflowState) -> NodeResult:
        """ìˆ˜ì§‘ ì™„ë£Œ"""
        data = state.get("data", {})

        return NodeResult(
            success=True,
            data={
                "final_collected_count": data.get("collected_count", 0),
                "keywords_searched": data.get("searched_keywords", []),
                "pages_analyzed": data.get("pages_analyzed", 0),
                "completed": True,
            }
        )

    async def _error_handler(self, state: WorkflowState) -> NodeResult:
        """ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬"""
        error = state.get("error", "Unknown error")
        print(f"[CoupangWorkflow] Error handled: {error}")

        # ë³µêµ¬ ì‹œë„: ì—ëŸ¬ë¥¼ ê¸°ë¡í•˜ê³  ì™„ë£Œ ë‹¨ê³„ë¡œ ì´ë™í•˜ì—¬ ë¶€ë¶„ ì„±ê³µ ì²˜ë¦¬ (Graceful Shutdown)
        return NodeResult(
            success=True,
            data={"error_handled": True, "original_error": error},
            next_node="complete"
        )
